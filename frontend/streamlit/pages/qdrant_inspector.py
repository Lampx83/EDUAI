# streamlit/pages/qdrant_inspector.py

import pandas as pd
import streamlit as st

<<<<<<< HEAD
from config.settings import qdrant_service_options, normalize_qdrant_url
=======
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
from state.session import require_login
from services.qdrant_service import (
    list_collections,
    get_collection_detail,
    list_points,
    filter_points,
)

# =====================================================
# CONFIG
# =====================================================

DEFAULT_PAGE_SIZE = 50
MAX_PAGE_SIZE = 200

# =====================================================
# UI
# =====================================================

def render():
    if not require_login():
        return

    st.header("üß† Qdrant Inspector")
    st.caption("Tr√¨nh duy·ªát embeddings (read-only) ‚Äì ph·ª•c v·ª• debug & ki·ªÉm tra d·ªØ li·ªáu")

    token = st.session_state.token

    # -------------------------------------------------
<<<<<<< HEAD
    # Qdrant Service
    # -------------------------------------------------
    qdrant_opts = qdrant_service_options()
    qdrant_labels = [t[0] for t in qdrant_opts]
    qdrant_values = [t[1] for t in qdrant_opts]
    qdrant_idx = st.selectbox(
        "üîó Qdrant Service",
        range(len(qdrant_labels)),
        format_func=lambda i: qdrant_labels[i],
        key="inspector_qdrant_svc",
        help="Ch·ªçn Qdrant ƒë·ªÉ inspect. M·∫∑c ƒë·ªãnh: localhost (dev) ho·∫∑c eduai-qdrant (docker).",
    )
    qdrant_custom = st.text_input(
        "Ho·∫∑c nh·∫≠p ƒë·ªãa ch·ªâ Qdrant t√πy ch·ªânh",
        placeholder="http://host:6333 ho·∫∑c host:6333",
        key="inspector_qdrant_custom",
        help="N·∫øu nh·∫≠p URL ·ªü ƒë√¢y, h·ªá th·ªëng s·∫Ω d√πng Qdrant n√†y thay v√¨ l·ª±a ch·ªçn tr√™n.",
    )
    qdrant_url = normalize_qdrant_url(qdrant_custom) if (qdrant_custom and qdrant_custom.strip()) else qdrant_values[qdrant_idx]

    # -------------------------------------------------
    # LOAD COLLECTIONS
    # -------------------------------------------------
    try:
        collections = list_collections(token, qdrant_url=qdrant_url)
=======
    # LOAD COLLECTIONS
    # -------------------------------------------------
    try:
        collections = list_collections(token)
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
    except Exception as exc:
        st.error(f"Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch collections: {exc}")
        return

    if not collections:
        st.info("Qdrant ch∆∞a c√≥ collection n√†o")
        return

    # -------------------------------------------------
    # SELECT COLLECTION
    # -------------------------------------------------
    col = st.selectbox(
        "üì¶ Collection",
        collections,
        format_func=lambda c: c["name"],
    )

    col_name = col["name"]

    # -------------------------------------------------
    # COLLECTION DETAIL (SOURCE OF TRUTH)
    # -------------------------------------------------
    try:
<<<<<<< HEAD
        detail = get_collection_detail(col_name, token, qdrant_url=qdrant_url)
=======
        detail = get_collection_detail(col_name, token)
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
    except Exception as exc:
        st.error(f"L·ªói khi l·∫•y collection detail: {exc}")
        return

    st.subheader("üìä Collection Overview")
    st.caption(
        "Th√¥ng tin t·ªïng quan: **Points** = t·ªïng s·ªë vector; **Indexed** = s·ªë vector ƒë√£ index; **Segments** = s·ªë segment; "
        "**Vector size** = chi·ªÅu vector; **Distance** = h√†m kho·∫£ng c√°ch (Cosine, Euclid, ‚Ä¶); **Status** = tr·∫°ng th√°i collection."
    )

    points_count = detail.get("points_count", 0)
    indexed_count = detail.get("indexed_vectors_count", 0)
    segments_count = detail.get("segments_count", 0)
    status = detail.get("status", "‚Äî")
    coll_name = detail.get("name", col_name)

    vectors = detail.get("vectors", {})
    vector_size = "‚Äî"
    distance = "‚Äî"
    if isinstance(vectors, dict) and vectors:
        first = next(iter(vectors.values()))
        vector_size = first.get("size", "‚Äî")
        distance = first.get("distance", "‚Äî")

    st.text(f"üì¶ {coll_name}  ‚Ä¢  Status: {status}")

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("Points", points_count)
    c2.metric("Indexed", indexed_count)
    c3.metric("Segments", segments_count)
    c4.metric("Vector size", vector_size)
    c5.metric("Distance", distance)

    st.subheader("üß± Payload Schema")
    st.caption(
        "C·∫•u tr√∫c metadata g·∫Øn v·ªõi m·ªói point (key ‚Üí ki·ªÉu d·ªØ li·ªáu). Payload d√πng ƒë·ªÉ l·ªçc v√† hi·ªÉn th·ªã, kh√¥ng d√πng khi t√≠nh kho·∫£ng c√°ch vector. "
        "Schema ƒë∆∞·ª£c suy ra t·ª´ m·∫´u d·ªØ li·ªáu trong collection."
    )
    st.json(detail.get("payload_schema", {}))

    # =================================================
    # FILTER
    # =================================================
    st.divider()
    st.subheader("üîç Filter points (payload)")
    st.caption(
        "L·ªçc points theo metadata (payload). ƒêi·ªÅn **file_hash**, **section_id** ho·∫∑c **chunk_id** r·ªìi b·∫≠t \"√Åp d·ª•ng filter\" "
        "ƒë·ªÉ ch·ªâ xem c√°c point th·ªèa ƒëi·ªÅu ki·ªán; ƒë·ªÉ tr·ªëng = kh√¥ng l·ªçc theo tr∆∞·ªùng ƒë√≥."
    )

    f1, f2, f3 = st.columns(3)

    with f1:
        file_hash = st.text_input("file_hash")

    with f2:
        section_id = st.text_input("section_id")

    with f3:
        chunk_id = st.number_input(
            "chunk_id",
            min_value=0,
            step=1,
            value=0,
        )

    use_filter = st.checkbox("√Åp d·ª•ng filter")

    # =================================================
    # PAGINATION
    # =================================================
    st.divider()
    st.subheader("üìÑ Browse points")
    st.caption(
        "Duy·ªát points theo trang: **S·ªë point / trang** = bao nhi√™u b·∫£n ghi m·ªói l·∫ßn; "
        "**Offset** = b·ªè qua bao nhi√™u point t·ª´ ƒë·∫ßu collection r·ªìi m·ªõi l·∫•y. "
        "V√≠ d·ª•: Offset 0 + 50/trang ‚Üí trang 1; Offset 50 + 50/trang ‚Üí trang 2."
    )

    p1, p2 = st.columns(2)

    with p1:
        limit = st.slider(
            "S·ªë point / trang",
            min_value=10,
            max_value=MAX_PAGE_SIZE,
            value=DEFAULT_PAGE_SIZE,
            step=10,
            help="S·ªë point t·ªëi ƒëa tr·∫£ v·ªÅ m·ªói l·∫ßn (k√≠ch th∆∞·ªõc trang).",
        )

    with p2:
        offset = st.number_input(
            "Offset (b·ªè qua N point ƒë·∫ßu)",
            min_value=0,
            step=limit,
            value=0,
            help="S·ªë point b·ªè qua t·ª´ ƒë·∫ßu collection tr∆∞·ªõc khi l·∫•y. Offset=0 l√† trang 1, Offset=limit l√† trang 2, Offset=2√ólimit l√† trang 3, ...",
        )

    # -------------------------------------------------
    # LOAD POINTS
    # -------------------------------------------------
    try:
        if use_filter:
            points = filter_points(
                collection=col_name,
                token=token,
                file_hash=file_hash or None,
                section_id=section_id or None,
                chunk_id=chunk_id if chunk_id > 0 else None,
                limit=limit,
<<<<<<< HEAD
                qdrant_url=qdrant_url,
=======
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
            )
        else:
            points = list_points(
                collection=col_name,
                token=token,
                limit=limit,
                offset=offset,
<<<<<<< HEAD
                qdrant_url=qdrant_url,
=======
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
            )

    except Exception as exc:
        st.error(f"L·ªói khi load points: {exc}")
        return

    if not points:
        st.info("Kh√¥ng c√≥ point n√†o ph√π h·ª£p")
        return

    # =================================================
    # TABLE VIEW
    # =================================================
    # Chi·ªÅu vector l·∫•y t·ª´ collection (m·ªçi point trong collection c√πng dimension; API kh√¥ng tr·∫£ vector khi scroll)
    collection_vector_size = None
    if detail.get("vectors"):
        first_vec = next(iter(detail["vectors"].values()), None)
        if first_vec and "size" in first_vec:
            collection_vector_size = first_vec["size"]

    # Thu th·∫≠p m·ªçi key payload (th·ª© t·ª± ∆∞u ti√™n r·ªìi alphabet)
    known_order = ("file_hash", "chunk_id", "section_id", "token_estimate", "text", "content", "source")
    all_keys = set()
    for p in points:
        all_keys.update((p.get("payload") or {}).keys())
    ordered_keys = [k for k in known_order if k in all_keys]
    ordered_keys += sorted(all_keys - set(ordered_keys))

    def _preview(val, max_len=80):
        if val is None:
            return None
        s = str(val)
        return (s[:max_len] + "‚Ä¶") if len(s) > max_len else s

    st.caption(
        "B·∫£ng hi·ªÉn th·ªã **id**, to√†n b·ªô **payload** (text/content r√∫t g·ªçn 80 k√Ω t·ª±), **vector_dim**. "
        "Chi ti·∫øt ƒë·∫ßy ƒë·ªß t·ª´ng point ·ªü ph·∫ßn b√™n d∆∞·ªõi."
    )
    rows = []
    for p in points:
        payload = p.get("payload") or {}
        row = {"id": p.get("id")}
        for k in ordered_keys:
            v = payload.get(k)
            if k in ("text", "content") and isinstance(v, str):
                row[k] = _preview(v, 80)
            elif isinstance(v, str) and len(v) > 60:
                row[k] = _preview(v, 60)
            else:
                row[k] = v
        row["vector_dim"] = p.get("vector_size") or collection_vector_size
        rows.append(row)

    df = pd.DataFrame(rows)

    st.dataframe(df, use_container_width=True)

    # =================================================
    # DETAIL VIEW
    # =================================================
    st.subheader("üîé Chi ti·∫øt point")

    point_ids = [p["id"] for p in points]

    selected_id = st.selectbox(
        "Ch·ªçn point",
        point_ids,
        format_func=lambda x: str(x),
    )

    selected_point = next(
        p for p in points if p["id"] == selected_id
    )

    st.text(f"Point ID: {selected_point.get('id')}")
    if selected_point.get("score") is not None:
        st.text(f"Score: {selected_point.get('score')}")

    payload = selected_point.get("payload") or {}
    if payload:
        st.caption("Payload (key ‚Üí value)")
        for k in sorted(payload.keys()):
            v = payload[k]
            if isinstance(v, str) and len(v) > 200:
                st.text(f"  {k}: {v[:200]}‚Ä¶")
            else:
                st.text(f"  {k}: {v}")

    with st.expander("üìå Payload (JSON)"):
        st.json(payload)

    with st.expander("üß† Vector info"):
        st.write(f"Vector dimension: {collection_vector_size or selected_point.get('vector_size') or '‚Äî'}")

    st.caption("‚ö†Ô∏è Vector raw kh√¥ng ƒë∆∞·ª£c hi·ªÉn th·ªã ƒë·ªÉ ƒë·∫£m b·∫£o hi·ªáu nƒÉng & an to√†n")
