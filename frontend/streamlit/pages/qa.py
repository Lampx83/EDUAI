# streamlit/pages/qa.py

import pandas as pd
import streamlit as st
<<<<<<< HEAD
from datetime import datetime

from config.settings import qdrant_service_options, normalize_qdrant_url
from services.api_client import qa, get_me
=======

from services.api_client import qa
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
from services.qdrant_service import list_collections
from state.session import require_login


<<<<<<< HEAD
def _ensure_qa_history_by_user():
    if "qa_history_by_user" not in st.session_state:
        st.session_state.qa_history_by_user = {}


def _current_username(token: str) -> str | None:
    """Username c·ªßa t√†i kho·∫£n ƒëang ƒëƒÉng nh·∫≠p (ƒë·ªÉ ch·ªâ hi·ªÉn th·ªã l·ªãch s·ª≠ c·ªßa user n√†y)."""
    if "current_username" in st.session_state and st.session_state.current_username:
        return st.session_state.current_username
    me = get_me(token)
    if me and me.get("username"):
        st.session_state.current_username = me["username"]
        return me["username"]
    return None


=======
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
def render():
    if not require_login():
        return

<<<<<<< HEAD
    _ensure_qa_history_by_user()
    token = st.session_state.token
    current_user = _current_username(token)

=======
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
    st.header("ü§ñ H·ªèi ƒë√°p v·ªõi AI")
    st.caption(
        "**Demo RAG:** T√≠nh nƒÉng n√†y d√πng ƒë·ªÉ demo RAG (Retrieval-Augmented Generation). "
        "H·ªá th·ªëng (1) t√¨m c√°c ƒëo·∫°n t√†i li·ªáu li√™n quan (semantic search), (2) g·ª≠i l√†m context cho AI, "
        "(3) AI **ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi d·ª±a tr√™n context ƒë∆∞·ª£c cung c·∫•p** ‚Äî kh√¥ng d√πng ki·∫øn th·ª©c b√™n ngo√†i. "
        "N·∫øu context kh√¥ng ƒë·ªß, AI s·∫Ω n√≥i r√µ kh√¥ng c√≥ th√¥ng tin. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
    )

<<<<<<< HEAD
    # --------------------------------------------------
    # L·ªãch s·ª≠ tr√≤ chuy·ªán (ch·ªâ c·ªßa t√†i kho·∫£n hi·ªán t·∫°i)
    # --------------------------------------------------
    with st.expander("üìú L·ªãch s·ª≠ tr√≤ chuy·ªán", expanded=False):
        if not current_user:
            st.caption("Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c t√†i kho·∫£n (token). Ch·ªâ hi·ªÉn th·ªã l·ªãch s·ª≠ c·ªßa phi√™n n√†y.")
            history_list = st.session_state.qa_history_by_user.get("__session__", [])
        else:
            st.caption(f"L·ªãch s·ª≠ c·ªßa t√†i kho·∫£n **{current_user}**.")
            history_list = st.session_state.qa_history_by_user.get(current_user, [])
        if not history_list:
            st.info("Ch∆∞a c√≥ l·ªãch s·ª≠. H·ªèi AI ƒë·ªÉ l∆∞u v√†o ƒë√¢y.")
        else:
            for i, item in enumerate(reversed(history_list[-50:])):  # 50 g·∫ßn nh·∫•t
                created = item.get("created_at", "")
                q = item.get("question", "")[:60] + ("‚Ä¶" if len(item.get("question", "")) > 60 else "")
                with st.expander(f"{created} ‚Äî {q}", expanded=False):
                    st.write("**C√¢u h·ªèi:**")
                    st.write(item.get("question", ""))
                    st.write("**Tr·∫£ l·ªùi:**")
                    st.markdown(item.get("answer", ""))

    # --------------------------------------------------
    # Qdrant Service + PARAMS
    # --------------------------------------------------
    qdrant_opts = qdrant_service_options()
    qdrant_labels = [t[0] for t in qdrant_opts]
    qdrant_values = [t[1] for t in qdrant_opts]
    qdrant_idx = st.selectbox(
        "üîó Qdrant Service",
        range(len(qdrant_labels)),
        format_func=lambda i: qdrant_labels[i],
        key="qa_qdrant_svc",
        help="Ch·ªçn Qdrant ƒë·ªÉ t√¨m context. M·∫∑c ƒë·ªãnh: localhost (dev) ho·∫∑c eduai-qdrant (docker).",
    )
    qdrant_custom = st.text_input(
        "Ho·∫∑c nh·∫≠p ƒë·ªãa ch·ªâ Qdrant t√πy ch·ªânh",
        placeholder="http://host:6333 ho·∫∑c host:6333",
        key="qa_qdrant_custom",
        help="N·∫øu nh·∫≠p URL ·ªü ƒë√¢y, h·ªá th·ªëng s·∫Ω d√πng Qdrant n√†y thay v√¨ l·ª±a ch·ªçn tr√™n.",
    )
    qdrant_url = normalize_qdrant_url(qdrant_custom) if (qdrant_custom and qdrant_custom.strip()) else qdrant_values[qdrant_idx]

    try:
        collections_resp = list_collections(token, qdrant_url=qdrant_url)
=======
    token = st.session_state.token

    # --------------------------------------------------
    # PARAMS
    # --------------------------------------------------
    try:
        collections_resp = list_collections(token)
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
        collections = [c["name"] for c in collections_resp] if collections_resp else ["eduai_chunks"]
    except Exception:
        collections = ["eduai_chunks"]

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        collection_name = st.selectbox(
            "üì¶ Collection",
            collections,
            help="Collection Qdrant ch·ª©a embeddings ƒë·ªÉ t√¨m context.",
        )

    with col2:
        top_k = st.slider(
            "S·ªë context (Top K)",
            min_value=1,
            max_value=20,
            value=5,
            help="S·ªë ƒëo·∫°n t√†i li·ªáu t·ªëi ƒëa g·ª≠i l√†m context cho LLM.",
        )

    with col3:
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=0.7,
            step=0.1,
            help="0 = ch√≠nh x√°c, 2 = s√°ng t·∫°o h∆°n.",
        )

    with col4:
        use_threshold = st.checkbox("Ng∆∞·ª°ng ƒëi·ªÉm context", value=False)
        score_threshold = None
        if use_threshold:
            score_threshold = st.slider(
                "Score t·ªëi thi·ªÉu",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                key="qa_score_threshold",
            )

    question = st.text_area(
        "C√¢u h·ªèi c·ªßa b·∫°n",
        placeholder="V√≠ d·ª•: Quy ƒë·ªãnh v·ªÅ kinh t·∫ø qu·ªëc d√¢n? ƒêi·ªÅu ki·ªán tuy·ªÉn sinh? Ch√≠nh s√°ch h·ªçc ph√≠?",
        height=120,
        key="qa_question",
    )

<<<<<<< HEAD
    data_to_show = None
    if st.button("üîç H·ªèi AI", type="primary"):
        if not question.strip():
            st.warning("Vui l√≤ng nh·∫≠p c√¢u h·ªèi")
        else:
            with st.spinner("ƒêang t√¨m context v√† g·ªçi LLM..."):
                try:
                    data = qa(
                        question=question.strip(),
                        top_k=top_k,
                        temperature=temperature,
                        token=token,
                        collection_name=collection_name or None,
                        score_threshold=score_threshold,
                        qdrant_url=qdrant_url,
                    )
                    st.session_state.qa_last_result = data
                    st.session_state.qa_last_question = question.strip()
                    st.session_state.qa_feedback = None
                    # L∆∞u v√†o l·ªãch s·ª≠ ch·ªâ cho t√†i kho·∫£n hi·ªán t·∫°i
                    user_key = current_user if current_user else "__session__"
                    st.session_state.qa_history_by_user.setdefault(user_key, []).append({
                        "question": question.strip(),
                        "answer": data.get("answer") or "",
                        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
                    })
                    data_to_show = data
                except Exception as exc:
                    st.error(f"L·ªói khi g·ªçi API: {exc}")

    if data_to_show is None and st.session_state.get("qa_last_result"):
        data_to_show = st.session_state.qa_last_result

    if data_to_show:
        data = data_to_show
        # ---------- Question (echo) ----------
        st.subheader("‚ùì C√¢u h·ªèi")
        st.write(data.get("question", ""))
=======
    if st.button("üîç H·ªèi AI", type="primary"):
        if not question.strip():
            st.warning("Vui l√≤ng nh·∫≠p c√¢u h·ªèi")
            return

        with st.spinner("ƒêang t√¨m context v√† g·ªçi LLM..."):
            try:
                data = qa(
                    question=question.strip(),
                    top_k=top_k,
                    temperature=temperature,
                    token=token,
                    collection_name=collection_name or None,
                    score_threshold=score_threshold,
                )
            except Exception as exc:
                st.error(f"L·ªói khi g·ªçi API: {exc}")
                return

        # ---------- Question (echo) ----------
        st.subheader("‚ùì C√¢u h·ªèi")
        st.write(question.strip())
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56

        # ---------- Answer ----------
        st.subheader("üí° C√¢u tr·∫£ l·ªùi")
        answer = data.get("answer") or "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi."
        model_used = data.get("model_used")

        if model_used:
            st.caption(f"Model: **{model_used}**")

        st.markdown(answer)

<<<<<<< HEAD
        # ---------- Like / Dislike (b·∫•m l·∫°i c√πng n√∫t = x√≥a, hai n√∫t hi·ªán b√¨nh th∆∞·ªùng) ----------
        feedback = st.session_state.get("qa_feedback") or None
        bl, br = st.columns(2)
        with bl:
            label_like = "üëç ƒê√£ th√≠ch (b·∫•m ƒë·ªÉ b·ªè)" if feedback == "like" else "üëç Th√≠ch"
            if st.button(label_like, key="qa_like"):
                if feedback == "like":
                    st.session_state.qa_feedback = None
                else:
                    st.session_state.qa_feedback = "like"
                st.rerun()
        with br:
            label_dislike = "üëé ƒê√£ kh√¥ng th√≠ch (b·∫•m ƒë·ªÉ b·ªè)" if feedback == "dislike" else "üëé Kh√¥ng th√≠ch"
            if st.button(label_dislike, key="qa_dislike"):
                if feedback == "dislike":
                    st.session_state.qa_feedback = None
                else:
                    st.session_state.qa_feedback = "dislike"
                st.rerun()

=======
>>>>>>> 59e59ae0f1ae7f00b194320e3da9c0520b7f9c56
        st.download_button(
            "‚¨áÔ∏è T·∫£i c√¢u tr·∫£ l·ªùi (TXT)",
            data=answer,
            file_name="qa_answer.txt",
            mime="text/plain",
            key="qa_download_answer",
        )

        # ---------- Contexts summary ----------
        contexts = data.get("contexts", [])
        st.subheader("üìö Context ƒë√£ d√πng ƒë·ªÉ tr·∫£ l·ªùi")
        st.caption(
            "C√°c ƒëo·∫°n t√†i li·ªáu ƒë∆∞·ª£c t√¨m b·∫±ng semantic search v√† g·ª≠i cho LLM. "
            "Score = ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi c√¢u h·ªèi (0‚Äì1)."
        )

        if not contexts:
            st.info("Kh√¥ng c√≥ context n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng")
        else:
            scores = [c["score"] for c in contexts]
            st.metric("S·ªë context", len(contexts))
            st.caption(f"Score trung b√¨nh: {sum(scores) / len(scores):.4f} | Min: {min(scores):.4f} | Max: {max(scores):.4f}")

            # ---------- Table ----------
            st.markdown("**B·∫£ng context**")
            rows = []
            for idx, ctx in enumerate(contexts, start=1):
                text = ctx.get("text") or ""
                text_preview = (text[:80] + "‚Ä¶") if len(text) > 80 else text
                rows.append({
                    "#": idx,
                    "score": round(ctx["score"], 4),
                    "file_hash": ctx.get("file_hash"),
                    "chunk_id": ctx.get("chunk_id"),
                    "section_id": ctx.get("section_id"),
                    "text": text_preview,
                })
            df = pd.DataFrame(rows)
            st.dataframe(df, use_container_width=True)

            # ---------- Detail per context ----------
            st.markdown("**Chi ti·∫øt t·ª´ng context**")
            for idx, ctx in enumerate(contexts, start=1):
                title = (
                    f"[{idx}] score = {ctx['score']:.4f} | "
                    f"file_hash = {ctx.get('file_hash') or '‚Äî'} | "
                    f"chunk_id = {ctx.get('chunk_id')}"
                )
                with st.expander(title, expanded=(idx <= 2)):
                    c1, c2 = st.columns(2)
                    with c1:
                        st.write("**Metadata**")
                        st.write(f"- file_hash: `{ctx.get('file_hash') or '‚Äî'}`")
                        st.write(f"- chunk_id: `{ctx.get('chunk_id')}`")
                        st.write(f"- section_id: `{ctx.get('section_id') or '‚Äî'}`")
                        st.write(f"- token_estimate: `{ctx.get('token_estimate') or '‚Äî'}`")
                        st.write(f"- source: `{ctx.get('source') or '‚Äî'}`")
                        if ctx.get("id"):
                            st.write(f"- point id: `{ctx.get('id')}`")
                    with c2:
                        text = ctx.get("text") or "(tr·ªëng)"
                        st.write("**N·ªôi dung**")
                        st.text_area(
                            "N·ªôi dung",
                            value=text,
                            height=180,
                            key=f"qa_ctx_text_{idx}_{ctx.get('id', idx)}",
                            disabled=True,
                            label_visibility="collapsed",
                        )
                        st.download_button(
                            "‚¨áÔ∏è T·∫£i n·ªôi dung context",
                            data=text,
                            file_name=f"context_{ctx.get('file_hash', '')}_{ctx.get('chunk_id', idx)}.txt",
                            mime="text/plain",
                            key=f"qa_ctx_dl_{idx}_{ctx.get('id', idx)}",
                        )

        # ---------- Raw response ----------
        with st.expander("üì¶ Raw API Response", expanded=False):
            st.json(data)

    else:
        st.info("Nh·∫≠p c√¢u h·ªèi v√† b·∫•m **H·ªèi AI** ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
